{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d08d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e47a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f66b57c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d779f84",
   "metadata": {},
   "source": [
    "We consider a multi-resolution diffusion process where diffusion proceeds at a given resolution for $T_\\ell$ steps, then the variable is downsampled to produce the initial state of the next level:\n",
    "\n",
    "\n",
    "$$\n",
    "x_0^0 \\to x_1^0 \\to \\cdots \\to x_{T_0}^0 \\;\n",
    "\\xrightarrow{\\text{downsample}}\\; x_0^1 \\to x_1^1 \\to \\cdots \\to x_{T_1}^1 \\;\n",
    "\\xrightarrow{\\text{downsample}}\\; x_0^2 \\to \\cdots.\n",
    "$$\n",
    "\n",
    "\n",
    "Each **level** $\\ell$ has its own spatial resolution and its own noise schedule $\\{\\beta_t^\\ell\\}_{t=1}^{T_\\ell}$.\n",
    "Let $D_\\ell$ denote the fixed downsampling operator used to map $x_{T_\\ell}^\\ell$ into $x_0^{\\ell+1}$.\n",
    "\n",
    "\n",
    "We assume each level uses the standard DDPM forward dynamics:\n",
    "\n",
    "\n",
    "$$\n",
    "x_t^\\ell = \\sqrt{\\alpha_t^\\ell} \\; x_{t-1}^\\ell + \\sqrt{1-\\alpha_t^\\ell} \\; \\varepsilon_t,\n",
    "\\qquad \\varepsilon_t \\sim \\mathcal{N}(0, I).\n",
    "$$\n",
    "\n",
    "\n",
    "where $\\alpha_t^\\ell = 1 - \\beta_t^\\ell$ and $\\bar\\alpha_t^\\ell = \\prod_{s=1}^t \\alpha_s^\\ell$.\n",
    "\n",
    "\n",
    "Our goal is to derive:\n",
    "1. The **marginal** distribution $q(x_t^\\ell \\mid x_0^\\ell)$.\n",
    "2. The distribution of $x_0^{\\ell+1}$ given $x_0^\\ell$.\n",
    "3. A minimal PyTorch implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b2f816",
   "metadata": {},
   "source": [
    "- $d_\\ell$ denotes the dimension at level $\\ell$ (e.g. number of pixels * channels at that downsampled resolution).\n",
    "- All within-level transitions are linear-Gaussian and independent across injected noises.\n",
    "- $D_\\ell$ are linear downsampling operators (for $\\ell=1$ this maps from level 0 to level 1). Define $D_0 = I$ for convenience.\n",
    "- NOTE - for now downsamples should be linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f8bf4f",
   "metadata": {},
   "source": [
    "**Claim.** The marginal of $x_t^{(\\ell)}$ given the original fine $x_0^{(0)}$ is Gaussian,\n",
    "\n",
    "\n",
    "$$\n",
    "q\\big(x_t^{(\\ell)} \\mid x_0^{(0)}\\big) = \\mathcal{N}\\big(x_t^{(\\ell)};\\; \\mu_t^{(\\ell)},\\; \\Sigma_t^{(\\ell)}\\big),\n",
    "$$\n",
    "\n",
    "\n",
    "with\n",
    "\n",
    "\n",
    "$$\n",
    "\\mu_t^{(\\ell)} = \\sqrt{\\bar\\alpha_t^{(\\ell)}}\\, D_\\ell\\, \\sqrt{\\bar\\alpha_{T_{\\ell-1}}^{(\\ell-1)}}\\, D_{\\ell-1}\\, \\cdots\\, \\sqrt{\\bar\\alpha_{T_0}^{(0)}}\\, x_0^{(0)}.\n",
    "$$\n",
    "\n",
    "\n",
    "and the recursive covariance\n",
    "\n",
    "\n",
    "$$\n",
    "(1 - \\bar\\alpha_t^{(\\ell)})\\, I_{d_\\ell}\n",
    "   + \\bar\\alpha_t^{(\\ell)}\\!\\left(\n",
    "        D_\\ell\\, \\Sigma_{T_{\\ell-1}}^{(\\ell-1)}\\, D_\\ell^\\top \n",
    "        + \\Sigma^{\\mathrm{down}}_\\ell\n",
    "     \\right).\n",
    "$$\n",
    "\n",
    "\n",
    "(Interpret $\\Sigma_{T_{-1}}^{(-1)} = 0$ and $D_0 = I$.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f9df47",
   "metadata": {},
   "source": [
    "**Derivation.** Start from the within-level decomposition\n",
    "\n",
    "\n",
    "$$\n",
    "x_t^{(\\ell)} = \\sqrt{\\bar\\alpha_t^{(\\ell)}} x_0^{(\\ell)} + \\varepsilon_t^{(\\ell)}, \\qquad \\varepsilon_t^{(\\ell)}\\sim\\mathcal{N}(0,(1-\\bar\\alpha_t^{(\\ell)})I).\n",
    "$$\n",
    "\n",
    "\n",
    "Write the level-0 initialization of this level as\n",
    "\n",
    "\n",
    "$$\n",
    "x_0^{(\\ell)} = D_\\ell x_{T_{\\ell-1}}^{(\\ell-1)} + \\zeta_\\ell, \\qquad \\zeta_\\ell\\sim\\mathcal{N}(0,\\Sigma^{\\mathrm{down}}_\\ell).\n",
    "$$\n",
    "\n",
    "\n",
    "Substitute to get\n",
    "\n",
    "\n",
    "$$\n",
    "x_t^{(\\ell)} = \\sqrt{\\bar\\alpha_t^{(\\ell)}} D_\\ell x_{T_{\\ell-1}}^{(\\ell-1)} + \\sqrt{\\bar\\alpha_t^{(\\ell)}} \\zeta_\\ell + \\varepsilon_t^{(\\ell)}.\n",
    "$$\n",
    "\n",
    "\n",
    "Conditioning on $x_0^{(0)}$ we know $x_{T_{\\ell-1}}^{(\\ell-1)}$ has marginal mean $\\mu_{T_{\\ell-1}}^{(\\ell-1)}$ and covariance $\\Sigma_{T_{\\ell-1}}^{(\\ell-1)}$. Thus the mean is\n",
    "\n",
    "\n",
    "$$\n",
    "\\mu_t^{(\\ell)} = \\sqrt{\\bar\\alpha_t^{(\\ell)}} D_\\ell \\mu_{T_{\\ell-1}}^{(\\ell-1)}\n",
    "$$\n",
    "\n",
    "\n",
    "and the covariance is the sum of independent contributions:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\Sigma_t^{(\\ell)} \n",
    "    &= \\operatorname{Cov}\\big(\\sqrt{\\bar\\alpha_t^{(\\ell)}} D_\\ell x_{T_{\\ell-1}}^{(\\ell-1)}\\big) + \\operatorname{Cov}\\big(\\sqrt{\\bar\\alpha_t^{(\\ell)}} \\zeta_\\ell\\big) + \\operatorname{Cov}(\\varepsilon_t^{(\\ell)}) \\\\\n",
    "    &= \\bar\\alpha_t^{(\\ell)} D_\\ell \\Sigma_{T_{\\ell-1}}^{(\\ell-1)} D_\\ell^\\top \n",
    "        + \\bar\\alpha_t^{(\\ell)} \\Sigma^{\\mathrm{down}}_\\ell \n",
    "        +  (1-\\bar\\alpha_t^{(\\ell)}) I_{d_\\ell} \\\\\n",
    "&= (1 - \\bar\\alpha_t^{(\\ell)})\\, I_{d_\\ell}\n",
    "   + \\bar\\alpha_t^{(\\ell)}\\!\\left(\n",
    "        D_\\ell\\, \\Sigma_{T_{\\ell-1}}^{(\\ell-1)}\\, D_\\ell^\\top \n",
    "        + \\Sigma^{\\mathrm{down}}_\\ell\n",
    "     \\right).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "This recursive formula allows computing marginals level-by-level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc5ae465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4580ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_linear_beta_schedule(T: int, beta_start: float = 1e-4, beta_end: float = 0.02) -> torch.Tensor:\n",
    "    \"\"\"Return beta_1..beta_T (length-T tensor).\"\"\"\n",
    "    return torch.linspace(beta_start, beta_end, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5a8049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = make_linear_beta_schedule(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c988d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphas_bars_from_betas(betas: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    alphas = 1.0 - betas\n",
    "    alphas_bar = torch.cumprod(alphas, dim=0)\n",
    "    return alphas, alphas_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9df80284",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas, alphas_bar = alphas_bars_from_betas(betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "332fb4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_batch(x: torch.Tensor) -> torch.Tensor:\n",
    "    return x.view(x.size(0), -1)\n",
    "\n",
    "def unflatten(flat: torch.Tensor, sample_shape: Tuple[int, int, int]) -> torch.Tensor:\n",
    "    return flat.view(-1, *sample_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a518253f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d71826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class AvgPoolDownsample:\n",
    "    def __init__(self, kernel: int = 2, stride: Optional[int] = None):\n",
    "        self.kernel = kernel\n",
    "        self.stride = kernel if stride is None else stride\n",
    "\n",
    "    def D(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.nn.functional.avg_pool2d(x, kernel_size=self.kernel, stride=self.stride)\n",
    "\n",
    "    def DT(self, y: torch.Tensor) -> torch.Tensor:\n",
    "        k = self.kernel\n",
    "        y_expanded = y.repeat_interleave(k, dim=2).repeat_interleave(k, dim=3)\n",
    "        return y_expanded / (k * k)\n",
    "\n",
    "    def mat(self, in_shape: Tuple[int,int,int]) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns sparse COO matrix implementing avg-pool.\n",
    "        Shape: (d_out, d_in)\n",
    "        \"\"\"\n",
    "        C, H, W = in_shape\n",
    "        k = self.kernel\n",
    "        s = self.stride\n",
    "\n",
    "        if k != s:\n",
    "            raise NotImplementedError(\"Sparse matrix coded for non-overlapping pooling (kernel=stride).\")\n",
    "\n",
    "        if H % k != 0 or W % k != 0:\n",
    "            raise ValueError(\"H and W must be divisible by kernel for kernel=stride avg-pool.\")\n",
    "\n",
    "        H2 = H // k\n",
    "        W2 = W // k\n",
    "\n",
    "        d_in = C * H * W\n",
    "        d_out = C * H2 * W2\n",
    "\n",
    "        rows = []\n",
    "        cols = []\n",
    "        vals = []\n",
    "\n",
    "        # Index helpers\n",
    "        def in_index(c, h, w):\n",
    "            return c * (H * W) + h * W + w\n",
    "\n",
    "        def out_index(c, h2, w2):\n",
    "            return c * (H2 * W2) + h2 * W2 + w2\n",
    "\n",
    "        # Build sparse entries\n",
    "        for c in range(C):\n",
    "            for y2 in range(H2):\n",
    "                for x2 in range(W2):\n",
    "                    out_i = out_index(c, y2, x2)\n",
    "                    h0 = y2 * k\n",
    "                    w0 = x2 * k\n",
    "\n",
    "                    for i in range(k):\n",
    "                        for j in range(k):\n",
    "                            h = h0 + i\n",
    "                            w = w0 + j\n",
    "                            rows.append(out_i)\n",
    "                            cols.append(in_index(c, h, w))\n",
    "                            vals.append(1.0 / (k * k))\n",
    "\n",
    "        indices = torch.tensor([rows, cols], dtype=torch.long)\n",
    "        values = torch.tensor(vals, dtype=torch.float32)\n",
    "        D = torch.sparse_coo_tensor(indices, values, (d_out, d_in))\n",
    "\n",
    "        return D.coalesce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c5183b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "down = AvgPoolDownsample(kernel=2)\n",
    "D = down.mat((1,4,4))\n",
    "\n",
    "x = torch.arange(16, dtype=torch.float32).view(1,1,4,4)\n",
    "xf = x.view(-1)\n",
    "\n",
    "y_sparse = (D @ xf)\n",
    "y_true = torch.nn.functional.avg_pool2d(x, 2).view(-1)\n",
    "\n",
    "assert torch.allclose(y_sparse, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c1f4f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "818c3d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def precompute_t0_marginals_sparse(\n",
    "    downsamplers: list,\n",
    "    downsample_sigmas: list,\n",
    "    level_shapes: list\n",
    "):\n",
    "    \"\"\"\n",
    "    Precompute t=0 marginals (mean and covariance) for each level.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    downsamplers : list of AvgPoolDownsample\n",
    "        Each downsampler maps level l-1 -> l\n",
    "    downsample_sigmas : list of torch.Tensor or None\n",
    "        Covariance for downsample noise per level\n",
    "    level_shapes : list of tuples\n",
    "        [(C,H0,W0), (C,H1,W1), ...] include level 0\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    marginals : list of dicts per level with keys:\n",
    "        - 'mu0': sparse or dense linear map d_l x d0 (to multiply x0)\n",
    "        - 'Sigma0': dense covariance d_l x d_l\n",
    "        - 'd_out': output dimension\n",
    "    \"\"\"\n",
    "    L = len(level_shapes) - 1  # number of downsample steps\n",
    "    marginals = []\n",
    "\n",
    "    # Level 0: identity\n",
    "    C0,H0,W0 = level_shapes[0]\n",
    "    d0 = C0*H0*W0\n",
    "    marginals.append(dict(\n",
    "        mu0=torch.eye(d0),    # d0 x d0\n",
    "        Sigma0=torch.zeros((d0,d0)),\n",
    "        d_out=d0\n",
    "    ))\n",
    "\n",
    "    for l in range(1,L+1):\n",
    "        # previous level t0\n",
    "        prev = marginals[l-1]\n",
    "        mu_prev = prev['mu0']      # d_{l-1} x d0\n",
    "        Sigma_prev = prev['Sigma0']  # d_{l-1} x d_{l-1}\n",
    "\n",
    "        # downsample\n",
    "        D_l = downsamplers[l-1].mat(level_shapes[l-1])  # d_l x d_{l-1}, sparse\n",
    "        d_l = D_l.shape[0]\n",
    "\n",
    "        # propagate mean: mu0^{(l)} = D_l @ mu_prev\n",
    "        mu0_l = D_l @ mu_prev\n",
    "\n",
    "        # propagate covariance: Sigma0^{(l)} = D_l Sigma_prev D_l^T + Sigma_down\n",
    "        if downsample_sigmas is not None and downsample_sigmas[l-1] is not None:\n",
    "            Sigma_down = downsample_sigmas[l-1]\n",
    "        else:\n",
    "            Sigma_down = torch.zeros((d_l,d_l))\n",
    "        Sigma0_l = D_l @ Sigma_prev @ D_l.T + Sigma_down\n",
    "\n",
    "        marginals.append(dict(\n",
    "            mu0=mu0_l,\n",
    "            Sigma0=Sigma0_l,\n",
    "            d_out=d_l\n",
    "        ))\n",
    "\n",
    "    return marginals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5a4ee27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0: torch.Size([64, 64]) torch.Size([64, 64])\n",
      "Level 1: torch.Size([16, 64]) torch.Size([16, 16])\n",
      "Level 2: torch.Size([4, 64]) torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "# Example: 3 levels, 8x8 -> 4x4 -> 2x2, C=1\n",
    "level_shapes = [(1,8,8), (1,4,4), (1,2,2)]\n",
    "downsamplers = [AvgPoolDownsample(2), AvgPoolDownsample(2)]\n",
    "downsample_sigmas = [None, None]  # deterministic\n",
    "\n",
    "marginals_t0 = precompute_t0_marginals_sparse(downsamplers, downsample_sigmas, level_shapes)\n",
    "\n",
    "# Level 0\n",
    "print(\"Level 0:\", marginals_t0[0]['mu0'].shape, marginals_t0[0]['Sigma0'].shape)\n",
    "# Level 1\n",
    "print(\"Level 1:\", marginals_t0[1]['mu0'].shape, marginals_t0[1]['Sigma0'].shape)\n",
    "# Level 2\n",
    "print(\"Level 2:\", marginals_t0[2]['mu0'].shape, marginals_t0[2]['Sigma0'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66ffdf9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mu0': tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.]]),\n",
       " 'Sigma0': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " 'd_out': 64}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marginals_t0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00575936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgpool_downsample_sigma(d_in: int, kernel_size: int, sigma_in: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute downsample noise covariance for average pooling.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    d_in : int\n",
    "        Input dimension (flattened)\n",
    "    kernel_size : int\n",
    "        Pooling kernel (assumes square kernel)\n",
    "    sigma_in : float\n",
    "        Original isotropic input variance\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Sigma_down : torch.Tensor\n",
    "        Dense covariance d_out x d_out for injection after pooling\n",
    "    \"\"\"\n",
    "    factor = 1.0 / kernel_size**2\n",
    "    sigma_out = sigma_in * factor\n",
    "    sigma_extra = sigma_in - sigma_out\n",
    "    d_out = d_in // (kernel_size**2)\n",
    "    return sigma_extra * torch.eye(d_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde739a2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db025b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Optional, List\n",
    "\n",
    "@torch.no_grad()\n",
    "def precompute_t0_marginals_sparse_full(\n",
    "    downsamplers: List['AvgPoolDownsample'],\n",
    "    downsample_sigmas: Optional[List[torch.Tensor]],\n",
    "    level_shapes: List[tuple],\n",
    "    betas_per_level: List[torch.Tensor],\n",
    "    device: Optional[torch.device] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Precompute t=0 marginals (mean linear map and covariance) after downsampling,\n",
    "    taking into account the last DDPM marginal of the previous level. If \n",
    "    downsample_sigmas[l] is None, computes exact covariance for average pooling.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    downsamplers : list of AvgPoolDownsample\n",
    "        Each downsampler maps level l-1 -> l\n",
    "    downsample_sigmas : list of torch.Tensor or None\n",
    "        Covariance for downsample noise per level\n",
    "    level_shapes : list of tuples\n",
    "        [(C,H0,W0), (C,H1,W1), ...] include level 0\n",
    "    betas_per_level : list of torch.Tensor\n",
    "        DDPM betas per level (length T_l)\n",
    "    device : torch.device\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    marginals : list of dicts per level with keys:\n",
    "        - 'mu0': sparse linear map d_l x d0 (multiply by x0_flat)\n",
    "        - 'Sigma0': dense covariance d_l x d_l\n",
    "        - 'd_out': output dimension\n",
    "    \"\"\"\n",
    "    L = len(level_shapes) - 1  # number of downsample steps\n",
    "    marginals = []\n",
    "\n",
    "    # Level 0: identity\n",
    "    C0,H0,W0 = level_shapes[0]\n",
    "    d0 = C0*H0*W0\n",
    "    I0 = torch.eye(d0, device=device)\n",
    "    marginals.append(dict(\n",
    "        mu0=I0.to_sparse(),\n",
    "        Sigma0=torch.zeros((d0,d0), device=device),\n",
    "        d_out=d0\n",
    "    ))\n",
    "\n",
    "    for l in range(1, L+1):\n",
    "        prev = marginals[l-1]\n",
    "        mu0_prev = prev['mu0']       # sparse d_{l-1} x d0\n",
    "        Sigma0_prev = prev['Sigma0'] # dense d_{l-1} x d_{l-1}\n",
    "\n",
    "        # Previous level final marginal\n",
    "        betas_prev = betas_per_level[l-1].to(device)\n",
    "        alphas_prev = 1 - betas_prev\n",
    "        alphas_bar_prev = torch.cumprod(alphas_prev, dim=0)\n",
    "        alpha_bar_T_prev = alphas_bar_prev[-1] if alphas_bar_prev.numel() > 0 else 1.0\n",
    "\n",
    "        # Scale mean and covariance to previous level T\n",
    "        mu_T_prev = mu0_prev.clone()\n",
    "        if l-1 > 0:\n",
    "            mu_T_prev = torch.sqrt(alpha_bar_T_prev) * mu0_prev\n",
    "        Sigma_T_prev = (1 - alpha_bar_T_prev) * torch.eye(Sigma0_prev.shape[0], device=device) \\\n",
    "                       + alpha_bar_T_prev * Sigma0_prev\n",
    "\n",
    "        # downsample sparse matrix\n",
    "        D_l = downsamplers[l-1].mat(level_shapes[l-1])  # sparse d_l x d_{l-1}\n",
    "        d_l = D_l.shape[0]\n",
    "\n",
    "        # propagate mean and covariance through downsample\n",
    "        mu0_l = torch.sparse.mm(D_l, mu_T_prev)\n",
    "\n",
    "        # compute downsample noise if not given\n",
    "        if downsample_sigmas is None or downsample_sigmas[l-1] is None:\n",
    "            # assume AvgPoolDownsample\n",
    "            pool_kernel = downsamplers[l-1].kernel\n",
    "            # variance factor per output: sigma_out^2 = sigma_in^2 / k^2\n",
    "            sigma_in2 = torch.mean(torch.diag(Sigma_T_prev)) if Sigma_T_prev.numel() > 0 else 1.0\n",
    "            sigma_extra = sigma_in2 * (1 - 1.0 / pool_kernel**2)\n",
    "            Sigma_down = sigma_extra * torch.eye(d_l, device=device)\n",
    "        else:\n",
    "            Sigma_down = downsample_sigmas[l-1].to(device)\n",
    "\n",
    "        Sigma0_l = (D_l @ Sigma_T_prev.to_dense()) @ D_l.T.to_dense() + Sigma_down\n",
    "\n",
    "        marginals.append(dict(\n",
    "            mu0=mu0_l.coalesce(),\n",
    "            Sigma0=Sigma0_l,\n",
    "            d_out=d_l\n",
    "        ))\n",
    "\n",
    "    return marginals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a853ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_marginal(l: int, t: int, x0: torch.Tensor,\n",
    "                 marginals_t0: list,\n",
    "                 betas_per_level: list) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Return marginal mean and covariance of x_t^{(l)} given x0.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    l : int\n",
    "        Level index (0..L)\n",
    "    t : int\n",
    "        Time index within level l (0..T_l-1)\n",
    "    x0 : torch.Tensor\n",
    "        Flattened x0 of shape (d0, 1)\n",
    "    marginals_t0 : list\n",
    "        Precomputed t=0 marginals (output of precompute_t0_marginals_sparse_full)\n",
    "    betas_per_level : list of torch.Tensor\n",
    "        DDPM betas per level\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mu_t : torch.Tensor\n",
    "        Marginal mean at level l, shape (d_l, 1)\n",
    "    Sigma_t : torch.Tensor\n",
    "        Marginal covariance at level l, shape (d_l, d_l)\n",
    "    \"\"\"\n",
    "    # t=0 marginal for this level\n",
    "    m0 = marginals_t0[l]\n",
    "    mu0 = torch.sparse.mm(m0['mu0'], x0) if l > 0 else x0  # shape (d_l,1)\n",
    "    Sigma0 = m0['Sigma0']  # shape (d_l,d_l)\n",
    "\n",
    "    # within-level DDPM scaling\n",
    "    betas = betas_per_level[l].to(x0.device)\n",
    "    alphas = 1 - betas\n",
    "    alphas_bar = torch.cumprod(alphas, dim=0)\n",
    "    alpha_bar_t = alphas_bar[t]\n",
    "\n",
    "    # final marginal at time t\n",
    "    mu_t = torch.sqrt(alpha_bar_t) * mu0\n",
    "    Sigma_t = (1 - alpha_bar_t) * torch.eye(m0['d_out'], device=x0.device) + alpha_bar_t * Sigma0\n",
    "\n",
    "    return mu_t, Sigma_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77665d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfa579a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0101, 0.0101, 0.0101, 0.0102, 0.0102, 0.0102, 0.0103, 0.0103, 0.0103,\n",
       "        0.0104, 0.0104, 0.0104, 0.0105, 0.0105, 0.0105, 0.0106, 0.0106, 0.0106,\n",
       "        0.0107, 0.0107, 0.0107, 0.0108, 0.0108, 0.0108, 0.0109, 0.0109, 0.0109,\n",
       "        0.0110, 0.0110, 0.0110, 0.0111, 0.0111, 0.0111, 0.0112, 0.0112, 0.0112,\n",
       "        0.0113, 0.0113, 0.0113, 0.0114, 0.0114, 0.0114, 0.0115, 0.0115, 0.0115,\n",
       "        0.0116, 0.0116, 0.0116, 0.0117, 0.0117, 0.0117, 0.0118, 0.0118, 0.0118,\n",
       "        0.0119, 0.0119, 0.0119, 0.0120, 0.0120, 0.0120, 0.0121, 0.0121, 0.0121,\n",
       "        0.0122, 0.0122, 0.0122, 0.0123, 0.0123, 0.0123, 0.0124, 0.0124, 0.0124,\n",
       "        0.0125, 0.0125, 0.0125, 0.0126, 0.0126, 0.0126, 0.0127, 0.0127, 0.0127,\n",
       "        0.0128, 0.0128, 0.0128, 0.0129, 0.0129, 0.0129, 0.0130, 0.0130, 0.0130,\n",
       "        0.0131, 0.0131, 0.0131, 0.0132, 0.0132, 0.0132, 0.0133, 0.0133, 0.0133,\n",
       "        0.0134, 0.0134, 0.0134, 0.0135, 0.0135, 0.0135, 0.0136, 0.0136, 0.0136,\n",
       "        0.0137, 0.0137, 0.0137, 0.0138, 0.0138, 0.0138, 0.0139, 0.0139, 0.0139,\n",
       "        0.0140, 0.0140, 0.0140, 0.0141, 0.0141, 0.0141, 0.0142, 0.0142, 0.0142,\n",
       "        0.0143, 0.0143, 0.0143, 0.0144, 0.0144, 0.0144, 0.0145, 0.0145, 0.0145,\n",
       "        0.0146, 0.0146, 0.0146, 0.0147, 0.0147, 0.0147, 0.0148, 0.0148, 0.0148,\n",
       "        0.0149, 0.0149, 0.0149, 0.0150, 0.0150, 0.0150, 0.0150, 0.0151, 0.0151,\n",
       "        0.0151, 0.0152, 0.0152, 0.0152, 0.0153, 0.0153, 0.0153, 0.0154, 0.0154,\n",
       "        0.0154, 0.0155, 0.0155, 0.0155, 0.0156, 0.0156, 0.0156, 0.0157, 0.0157,\n",
       "        0.0157, 0.0158, 0.0158, 0.0158, 0.0159, 0.0159, 0.0159, 0.0160, 0.0160,\n",
       "        0.0160, 0.0161, 0.0161, 0.0161, 0.0162, 0.0162, 0.0162, 0.0163, 0.0163,\n",
       "        0.0163, 0.0164, 0.0164, 0.0164, 0.0165, 0.0165, 0.0165, 0.0166, 0.0166,\n",
       "        0.0166, 0.0167])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suppose we already have:\n",
    "# marginals_t0 = precompute_t0_marginals_sparse_full(...)\n",
    "T0 = 300\n",
    "T1 = 200\n",
    "T2 = 100\n",
    "betas = torch.linspace(1e-4,0.02,steps=T0+T1+T2)\n",
    "betas_per_level = [\n",
    "    betas[0:T0],\n",
    "    betas[T0:T1+T0],\n",
    "    betas[T1+T0:],\n",
    "]\n",
    "betas_per_level[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96f00ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0: torch.Size([64, 64]) torch.Size([64, 64])\n",
      "Level 1: torch.Size([16, 64]) torch.Size([16, 16])\n",
      "Level 2: torch.Size([4, 64]) torch.Size([4, 4])\n",
      "mu_t shape: torch.Size([16, 1])\n",
      "Sigma_t shape: torch.Size([16, 16])\n",
      "mu_t2 shape: torch.Size([4, 1])\n",
      "Sigma_t2 shape: torch.Size([4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2565],\n",
       "         [ 0.4394],\n",
       "         [ 0.0226],\n",
       "         [ 0.0798],\n",
       "         [-0.1536],\n",
       "         [-0.3669],\n",
       "         [ 0.2603],\n",
       "         [ 0.1496],\n",
       "         [-0.0044],\n",
       "         [ 0.0886],\n",
       "         [-0.2079],\n",
       "         [ 0.4561],\n",
       "         [-0.6858],\n",
       "         [ 0.1893],\n",
       "         [ 0.1255],\n",
       "         [ 0.0532]]),\n",
       " tensor([[0.9339, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.9339, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.9339, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.9339, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.9339, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9339, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9339, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9339, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9339,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.9339, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.9339, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.9339, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.9339, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.9339, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9339, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9339]]),\n",
       " tensor([[-0.0254],\n",
       "         [ 0.0385],\n",
       "         [-0.0310],\n",
       "         [ 0.0321]]),\n",
       " tensor([[0.9940, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.9940, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.9940, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.9940]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suppose we already have:\n",
    "level_shapes = [(1,8,8), (1,4,4), (1,2,2)]\n",
    "downsamplers = [AvgPoolDownsample(2), AvgPoolDownsample(2)]\n",
    "downsample_sigmas = [None, None]  # correctly handle variance scaling\n",
    "\n",
    "marginals_t0 = precompute_t0_marginals_sparse_full(\n",
    "    downsamplers, \n",
    "    downsample_sigmas,\n",
    "    level_shapes, \n",
    "    betas_per_level    \n",
    ")\n",
    "\n",
    "# Level 0\n",
    "print(\"Level 0:\", marginals_t0[0]['mu0'].shape, marginals_t0[0]['Sigma0'].shape)\n",
    "# Level 1\n",
    "print(\"Level 1:\", marginals_t0[1]['mu0'].shape, marginals_t0[1]['Sigma0'].shape)\n",
    "# Level 2\n",
    "print(\"Level 2:\", marginals_t0[2]['mu0'].shape, marginals_t0[2]['Sigma0'].shape)\n",
    "\n",
    "\n",
    "x0_flat = torch.randn((64,1))  # flattened level 0\n",
    "\n",
    "# Get marginal at level 1, t=3\n",
    "mu_t, Sigma_t = get_marginal(l=1, t=100, x0=x0_flat,\n",
    "                             marginals_t0=marginals_t0,\n",
    "                             betas_per_level=betas_per_level)\n",
    "\n",
    "print(\"mu_t shape:\", mu_t.shape)\n",
    "print(\"Sigma_t shape:\", Sigma_t.shape)\n",
    "\n",
    "# Get marginal at level 2, t=1\n",
    "mu_t2, Sigma_t2 = get_marginal(l=2, t=50, x0=x0_flat,\n",
    "                               marginals_t0=marginals_t0,\n",
    "                               betas_per_level=betas_per_level)\n",
    "\n",
    "print(\"mu_t2 shape:\", mu_t2.shape)\n",
    "print(\"Sigma_t2 shape:\", Sigma_t2.shape)\n",
    "\n",
    "mu_t, Sigma_t, mu_t2, Sigma_t2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0541a61d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aeab6bd2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd940a19",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72515b7d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
